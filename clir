function u0:0(i64) -> i64 windows_fastcall {
    sig0 = (i8) -> i64 windows_fastcall
    sig1 = (i64) -> i64 windows_fastcall

block0(v0: i64):
    v1 = iconst.i64 0
    v2 = iconst.i64 0x7ff6_7d47_86e0
    v3 = iconst.i64 0x7ff6_7d47_88a0
    v5 = iadd v0, v1  ; v1 = 0
    v6 = load.i8 v5
    brif v6, block2(v1), block3(v1)  ; v1 = 0, v1 = 0

block2(v7: i64):
    v13 -> v7
    v19 -> v7
    v8 = iadd.i64 v0, v7
    v9 = load.i8 v8
    v10 = call_indirect.i64 sig0, v2(v9)  ; v2 = 0x7ff6_7d47_86e0
    brif v10, block1(v10), block4

block4:
    v11 = iadd.i64 v0, v7
    v12 = load.i8 v11
    brif v12, block5, block6

block5:
    v14 = iadd.i64 v0, v13
    v15 = load.i8 v14
    v16 = call_indirect.i64 sig0, v2(v15)  ; v2 = 0x7ff6_7d47_86e0
    brif v16, block1(v16), block7

block7:
    v17 = iadd.i64 v0, v13
    v18 = load.i8 v17
    brif v18, block5, block6

block6:
    v20 = iadd.i64 v0, v7
    v21 = call_indirect.i64 sig1, v3(v20)  ; v3 = 0x7ff6_7d47_88a0
    brif v21, block1(v21), block8

block8:
    v22 = iadd.i64 v0, v19
    v23 = load.i8 v22
    v24 = call_indirect.i64 sig0, v2(v23)  ; v2 = 0x7ff6_7d47_86e0
    brif v24, block1(v24), block9

block9:
    v25 = iadd.i64 v0, v19
    v26 = load.i8 v25
    v27 = call_indirect.i64 sig0, v2(v26)  ; v2 = 0x7ff6_7d47_86e0
    brif v27, block1(v27), block10

block10:
    v28 = iadd.i64 v0, v19
    v29 = call_indirect.i64 sig1, v3(v28)  ; v3 = 0x7ff6_7d47_88a0
    brif v29, block1(v29), block11

block11:
    v30 = iadd.i64 v0, v19
    v31 = call_indirect.i64 sig1, v3(v30)  ; v3 = 0x7ff6_7d47_88a0
    brif v31, block1(v31), block12

block12:
    v32 = iadd.i64 v0, v19
    v33 = call_indirect.i64 sig1, v3(v32)  ; v3 = 0x7ff6_7d47_88a0
    brif v33, block1(v33), block13

block13:
    v34 = iadd.i64 v0, v19
    v35 = load.i8 v34
    v36 = iadd_imm v35, 1
    store v36, v34
    v37 = iadd.i64 v0, v19
    v38 = call_indirect.i64 sig1, v3(v37)  ; v3 = 0x7ff6_7d47_88a0
    brif v38, block1(v38), block14

block14:
    v39 = iadd.i64 v0, v19
    v40 = load.i8 v39
    v41 = iadd_imm v40, -1
    store v41, v39
    v42 = iadd.i64 v0, v19
    v43 = call_indirect.i64 sig1, v3(v42)  ; v3 = 0x7ff6_7d47_88a0
    brif v43, block1(v43), block15

block15:
    v44 = iadd_imm.i64 v19, 0
    v45 = iadd_imm.i64 v19, 0x7530
    v46 = icmp_imm slt v44, 0
    v47 = select v46, v45, v44
    v52 -> v47
    v55 -> v47
    v48 = iadd.i64 v0, v47
    v49 = call_indirect.i64 sig1, v3(v48)  ; v3 = 0x7ff6_7d47_88a0
    brif v49, block1(v49), block16

block16:
    v50 = iadd.i64 v0, v47
    v51 = load.i8 v50
    brif v51, block17, block18

block17:
    v53 = iadd.i64 v0, v52
    v54 = load.i8 v53
    brif v54, block17, block18

block18:
    v56 = iadd.i64 v0, v47
    v57 = load.i8 v56
    v58 = call_indirect.i64 sig0, v2(v57)  ; v2 = 0x7ff6_7d47_86e0
    brif v58, block1(v58), block19

block19:
    v59 = iadd.i64 v0, v55
    v60 = load.i8 v59
    v61 = call_indirect.i64 sig0, v2(v60)  ; v2 = 0x7ff6_7d47_86e0
    brif v61, block1(v61), block20

block20:
    v62 = iadd.i64 v0, v55
    v63 = load.i8 v62
    brif v63, block2(v55), block3(v55)

block3(v64: i64):
    v65 = iadd.i64 v0, v64
    v66 = load.i8 v65
    v67 = iadd_imm v66, 8
    store v67, v65
    v68 = iadd.i64 v0, v64
    v69 = load.i8 v68
    brif v69, block21(v64), block22(v64)

block21(v70: i64):
    v71 = iadd_imm v70, 1
    v72 = iadd_imm v70, -29999
    v73 = icmp_imm slt v71, 0x7530
    v74 = select v73, v71, v72
    v75 = iadd.i64 v0, v74
    v76 = load.i8 v75
    v77 = iadd_imm v76, 4
    store v77, v75
    v78 = iadd.i64 v0, v74
    v79 = load.i8 v78
    brif v79, block23(v74), block24(v74)

block23(v80: i64):
    v81 = iadd_imm v80, 1
    v82 = iadd_imm v80, -29999
    v83 = icmp_imm slt v81, 0x7530
    v84 = select v83, v81, v82
    v85 = iadd.i64 v0, v84
    v86 = load.i8 v85
    v87 = iadd_imm v86, 2
    store v87, v85
    v88 = iadd_imm v84, 1
    v89 = iadd_imm v84, -29999
    v90 = icmp_imm slt v88, 0x7530
    v91 = select v90, v88, v89
    v92 = iadd.i64 v0, v91
    v93 = load.i8 v92
    v94 = iadd_imm v93, 3
    store v94, v92
    v95 = iadd_imm v91, 1
    v96 = iadd_imm v91, -29999
    v97 = icmp_imm slt v95, 0x7530
    v98 = select v97, v95, v96
    v99 = iadd.i64 v0, v98
    v100 = load.i8 v99
    v101 = iadd_imm v100, 3
    store v101, v99
    v102 = iadd_imm v98, 1
    v103 = iadd_imm v98, -29999
    v104 = icmp_imm slt v102, 0x7530
    v105 = select v104, v102, v103
    v106 = iadd.i64 v0, v105
    v107 = load.i8 v106
    v108 = iadd_imm v107, 1
    store v108, v106
    v109 = iadd_imm v105, -4
    v110 = iadd_imm v105, 0x752c
    v111 = icmp_imm slt v109, 0
    v112 = select v111, v110, v109
    v113 = iadd.i64 v0, v112
    v114 = load.i8 v113
    v115 = iadd_imm v114, -1
    store v115, v113
    v116 = iadd.i64 v0, v112
    v117 = load.i8 v116
    brif v117, block23(v112), block24(v112)

block24(v118: i64):
    v119 = iadd_imm v118, 1
    v120 = iadd_imm v118, -29999
    v121 = icmp_imm slt v119, 0x7530
    v122 = select v121, v119, v120
    v123 = iadd.i64 v0, v122
    v124 = load.i8 v123
    v125 = iadd_imm v124, 1
    store v125, v123
    v126 = iadd_imm v122, 1
    v127 = iadd_imm v122, -29999
    v128 = icmp_imm slt v126, 0x7530
    v129 = select v128, v126, v127
    v130 = iadd.i64 v0, v129
    v131 = load.i8 v130
    v132 = iadd_imm v131, 1
    store v132, v130
    v133 = iadd_imm v129, 1
    v134 = iadd_imm v129, -29999
    v135 = icmp_imm slt v133, 0x7530
    v136 = select v135, v133, v134
    v137 = iadd.i64 v0, v136
    v138 = load.i8 v137
    v139 = iadd_imm v138, -1
    store v139, v137
    v140 = iadd_imm v136, 2
    v141 = iadd_imm v136, -29998
    v142 = icmp_imm slt v140, 0x7530
    v143 = select v142, v140, v141
    v144 = iadd.i64 v0, v143
    v145 = load.i8 v144
    v146 = iadd_imm v145, 1
    store v146, v144
    v147 = iadd.i64 v0, v143
    v148 = load.i8 v147
    brif v148, block25(v143), block26(v143)

block25(v149: i64):
    v150 = iadd_imm v149, -1
    v151 = iadd_imm v149, 0x752f
    v152 = icmp_imm slt v150, 0
    v153 = select v152, v151, v150
    v154 = iadd.i64 v0, v153
    v155 = load.i8 v154
    brif v155, block25(v153), block26(v153)

block26(v156: i64):
    v157 = iadd_imm v156, -1
    v158 = iadd_imm v156, 0x752f
    v159 = icmp_imm slt v157, 0
    v160 = select v159, v158, v157
    v161 = iadd.i64 v0, v160
    v162 = load.i8 v161
    v163 = iadd_imm v162, -1
    store v163, v161
    v164 = iadd.i64 v0, v160
    v165 = load.i8 v164
    brif v165, block21(v160), block22(v160)

block22(v166: i64):
    v167 = iadd_imm v166, 2
    v168 = iadd_imm v166, -29998
    v169 = icmp_imm slt v167, 0x7530
    v170 = select v169, v167, v168
    v171 = iadd.i64 v0, v170
    v172 = load.i8 v171
    v173 = call_indirect.i64 sig0, v2(v172)  ; v2 = 0x7ff6_7d47_86e0
    brif v173, block1(v173), block27

block27:
    v174 = iadd_imm.i64 v170, 1
    v175 = iadd_imm.i64 v170, -29999
    v176 = icmp_imm slt v174, 0x7530
    v177 = select v176, v174, v175
    v178 = iadd.i64 v0, v177
    v179 = load.i8 v178
    v180 = iadd_imm v179, -3
    store v180, v178
    v181 = iadd.i64 v0, v177
    v182 = load.i8 v181
    v183 = call_indirect.i64 sig0, v2(v182)  ; v2 = 0x7ff6_7d47_86e0
    brif v183, block1(v183), block28

block28:
    v184 = iadd.i64 v0, v177
    v185 = load.i8 v184
    v186 = iadd_imm v185, 7
    store v186, v184
    v187 = iadd.i64 v0, v177
    v188 = load.i8 v187
    v189 = call_indirect.i64 sig0, v2(v188)  ; v2 = 0x7ff6_7d47_86e0
    brif v189, block1(v189), block29

block29:
    v190 = iadd.i64 v0, v177
    v191 = load.i8 v190
    v192 = call_indirect.i64 sig0, v2(v191)  ; v2 = 0x7ff6_7d47_86e0
    brif v192, block1(v192), block30

block30:
    v193 = iadd.i64 v0, v177
    v194 = load.i8 v193
    v195 = iadd_imm v194, 3
    store v195, v193
    v196 = iadd.i64 v0, v177
    v197 = load.i8 v196
    v198 = call_indirect.i64 sig0, v2(v197)  ; v2 = 0x7ff6_7d47_86e0
    brif v198, block1(v198), block31

block31:
    v199 = iadd_imm.i64 v177, 2
    v200 = iadd_imm.i64 v177, -29998
    v201 = icmp_imm slt v199, 0x7530
    v202 = select v201, v199, v200
    v203 = iadd.i64 v0, v202
    v204 = load.i8 v203
    v205 = call_indirect.i64 sig0, v2(v204)  ; v2 = 0x7ff6_7d47_86e0
    brif v205, block1(v205), block32

block32:
    v206 = iadd_imm.i64 v202, -1
    v207 = iadd_imm.i64 v202, 0x752f
    v208 = icmp_imm slt v206, 0
    v209 = select v208, v207, v206
    v210 = iadd.i64 v0, v209
    v211 = load.i8 v210
    v212 = iadd_imm v211, -1
    store v212, v210
    v213 = iadd.i64 v0, v209
    v214 = load.i8 v213
    v215 = call_indirect.i64 sig0, v2(v214)  ; v2 = 0x7ff6_7d47_86e0
    brif v215, block1(v215), block33

block33:
    v216 = iadd_imm.i64 v209, -1
    v217 = iadd_imm.i64 v209, 0x752f
    v218 = icmp_imm slt v216, 0
    v219 = select v218, v217, v216
    v220 = iadd.i64 v0, v219
    v221 = load.i8 v220
    v222 = call_indirect.i64 sig0, v2(v221)  ; v2 = 0x7ff6_7d47_86e0
    brif v222, block1(v222), block34

block34:
    v223 = iadd.i64 v0, v219
    v224 = load.i8 v223
    v225 = iadd_imm v224, 3
    store v225, v223
    v226 = iadd.i64 v0, v219
    v227 = load.i8 v226
    v228 = call_indirect.i64 sig0, v2(v227)  ; v2 = 0x7ff6_7d47_86e0
    brif v228, block1(v228), block35

block35:
    v229 = iadd.i64 v0, v219
    v230 = load.i8 v229
    v231 = iadd_imm v230, -6
    store v231, v229
    v232 = iadd.i64 v0, v219
    v233 = load.i8 v232
    v234 = call_indirect.i64 sig0, v2(v233)  ; v2 = 0x7ff6_7d47_86e0
    brif v234, block1(v234), block36

block36:
    v235 = iadd.i64 v0, v219
    v236 = load.i8 v235
    v237 = iadd_imm v236, -8
    store v237, v235
    v238 = iadd.i64 v0, v219
    v239 = load.i8 v238
    v240 = call_indirect.i64 sig0, v2(v239)  ; v2 = 0x7ff6_7d47_86e0
    brif v240, block1(v240), block37

block37:
    v241 = iadd_imm.i64 v219, 2
    v242 = iadd_imm.i64 v219, -29998
    v243 = icmp_imm slt v241, 0x7530
    v244 = select v243, v241, v242
    v245 = iadd.i64 v0, v244
    v246 = load.i8 v245
    v247 = iadd_imm v246, 1
    store v247, v245
    v248 = iadd.i64 v0, v244
    v249 = load.i8 v248
    v250 = call_indirect.i64 sig0, v2(v249)  ; v2 = 0x7ff6_7d47_86e0
    brif v250, block1(v250), block38

block38:
    v251 = iadd_imm.i64 v244, 1
    v252 = iadd_imm.i64 v244, -29999
    v253 = icmp_imm slt v251, 0x7530
    v254 = select v253, v251, v252
    v255 = iadd.i64 v0, v254
    v256 = load.i8 v255
    v257 = iadd_imm v256, 2
    store v257, v255
    v258 = iadd.i64 v0, v254
    v259 = load.i8 v258
    v260 = call_indirect.i64 sig0, v2(v259)  ; v2 = 0x7ff6_7d47_86e0
    brif v260, block1(v260), block39

block39:
    return v1  ; v1 = 0

block1(v4: i64):
    return v4
}
